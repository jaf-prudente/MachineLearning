{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ff6355-c51d-4b42-9261-980e70156198",
   "metadata": {},
   "source": [
    "# Carga de datos con 'read_csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67acbe-e632-46ba-9dc0-fd9ac8d6f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Importamos bibliotecas.\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c728a07-75ef-43a3-aa58-d3f7bd7d4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Lo más cómodo es asiganr el la dirección del dataset en una variable.\n",
    "datasets_path = '../datasets/'\n",
    "file_name = 'titanic/titanic3.csv'\n",
    "full_path = os.path.join(datasets_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f239d-dca5-41c9-ba5e-ab681d1a0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Veamos algunos argumentos del 'read_csv' para abrir el archivo.\n",
    "\n",
    "# 'filepath_or_buffer' es la dirección del dataset.\n",
    "# 'sep' es el tipo de separador que tiene.\n",
    "# 'dtype' es cómo se van a guardar los datos, puede ser 'int', 'float', etc.\n",
    "# 'header' especifíca el dónde está el cabezal.\n",
    "# 'names' indica cómo se llama cada una de las columnas.\n",
    "# 'skiprows' es para comenzar a leer después de algunoas líneas.\n",
    "# 'skip_blank_lines' sirve para saltar valores en blanco.\n",
    "# 'na_filter' elimina lineas con valores desconocidos cono NAN.\n",
    "data = pd.read_csv(filepath_or_buffer = full_path, sep = ',', dtype = None, header = 0, names = None, skiprows = 0, skip_blank_lines = False, na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed726c-abce-451b-931e-4e01c773a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# 'head()' funciona tal cual como el 'head' en linux.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864f268-488a-46b9-8b1c-e1c93bf8f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Carguemos otro archivo.\n",
    "data2 = pd.read_csv(datasets_path + '/customer-churn-model/Customer Churn Model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a2256-be3a-44c9-8a98-19540bb330fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Corroboramos que lo cargamos bien.\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c78123-fbbf-43c5-8af4-fbf47c51cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Con el método 'columns.values' corroboramos las etiquetas del cabezal.\n",
    "data2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ee3ca-6f6c-418a-aa3d-5b3ca5b5a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Cambiémoslo, para ello cargamos los nuevos valores.\n",
    "data_cols = pd.read_csv(datasets_path + 'customer-churn-model/Customer Churn Columns.csv')\n",
    "\n",
    "# Cambiamos el formato a una lista (antes era un dataframe de pandas).\n",
    "data_cols_list = data_cols['Column_Names'].tolist()\n",
    "\n",
    "# Ahora cargamos el 'txt' de antes pero con la espeficicación del cambio de columnas.\n",
    "data2 = pd.read_csv(datasets_path + '/customer-churn-model/Customer Churn Model.txt', header = None, names  = data_cols_list)\n",
    "\n",
    "# Corroboramos con un 'head' o con un 'data2.columns.values'.\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c43a43-f0fb-499c-8a3d-6b222d7b4c42",
   "metadata": {},
   "source": [
    "# Carga de datasets manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd33504-477e-4aae-8abf-1bddbb7fb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# También podemos extraer los datos a mano.\n",
    "# Esto sirve para nmo saturar la ram. \n",
    "# Ocuparemos 'open' por cómo carga datos.\n",
    "data3 = open(datasets_path + 'customer-churn-model/Customer Churn Model.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ead8ad-d3f7-48e4-bec0-52b6d6ca28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Ahora veamos qué etiquetas tienen las columnas.\n",
    "# Con 'readline()' leemos la primer línea de 'data3',\n",
    "# con 'strip()' eliminamos los espacios en blanco,\n",
    "# con 'split()' partimos todo el renglón con un delimitador.\n",
    "cols = data3.readline().strip().split(',')\n",
    "\n",
    "# Guardemos cuántas columnas hay con 'len()'.\n",
    "num_cols = len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53d601-eae5-41b9-bc7e-a55057c1aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Ahora vamos a crear un diccionario, cada entrada\n",
    "# será una columna que esté llena con un arreglo\n",
    "# con sus respectivos valores. Además veamos cuántas lineas tiene.\n",
    "\n",
    "# Definimos un contador de lineas.\n",
    "contador_lineas = 0\n",
    "\n",
    "# Definimos el diccionario.\n",
    "dict_data3 = {}\n",
    "\n",
    "# Lo llenamos, cada entrada del diccionario por \n",
    "# ahora será un arreglo vacio pero con el nombre\n",
    "# de su respectiva columna.\n",
    "for col in cols:\n",
    "    dict_data3[col] = []\n",
    "\n",
    "# Llenamos cada valor, de cada arreglo del diccionario. \n",
    "for linea in data3:\n",
    "    \n",
    "    # Cada 'linea' la tenemos que dividir como hicimos arriba con las columnas.\n",
    "    valor = linea.strip().split(',')\n",
    "    \n",
    "    # 'valor' es un arreglo y cada una de sus entradas es una entrada de cada arreglo del diccionario.\n",
    "    for i in range(len(cols)):\n",
    "        dict_data3[cols[i]].append( valor[i] )\n",
    "        \n",
    "    # Aumentamos el contador.\n",
    "    contador_lineas += 1\n",
    "\n",
    "# Imprimimos el número de filas y columnas.\n",
    "print(f'El dataset tiene {num_cols} columnas y {contador_lineas} lineas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1d31c-d6d2-46c0-9218-e4c38eb8ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Pero lo que hicimos es un diccionario. \n",
    "# Generalmente trabajaremos con 'dataframes' de pandas.\n",
    "dataframe3 = pd.DataFrame(dict_data3)\n",
    "\n",
    "# Para visualizarlo hagamos un 'head()'.\n",
    "dataframe3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc5c97-8060-4553-96b3-6ae3e9c7edc4",
   "metadata": {},
   "source": [
    "# Lectura y escritura de ficheros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489e9e9-9c09-4bd1-b406-472c31ae5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Ahora vamos a reescribir este archivo pero separándolo con tabs.\n",
    "\n",
    "# Definimos un archivo de entrada y otro de salida.\n",
    "infile = datasets_path + 'customer-churn-model/Customer Churn Model.txt'\n",
    "outfile = datasets_path + 'customer-churn-model/Tab Customer Churn Model.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265076a-88d7-49ff-8faf-1d29c4047a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Abrimos los dos archivos, uno en lectura y otro en escritura.\n",
    "with open(infile, 'r') as infile1:\n",
    "    with open(outfile, 'w') as outfile1:\n",
    "        \n",
    "        # Hacemos un for para leer todas las lineas, y formateartas.\n",
    "        for line in infile1:\n",
    "            fields = line.strip().split(',')\n",
    "            \n",
    "            # Escribimos los valores que separamos pero ahora los juntamos con un tabulador.\n",
    "            outfile1.write( '\\t'.join(fields) )\n",
    "            \n",
    "            # Damos un salto de linea.\n",
    "            outfile1.write( '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90719ad5-617f-47b9-9fee-8770a38cd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# Abrimos este nuevo archivo con delimitador '\\t'.\n",
    "dataframe4 = pd.read_csv(outfile, sep = '\\t')\n",
    "\n",
    "# Verificamos con un 'head()'.\n",
    "dataframe4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253e0ac-892f-45d0-a022-cd3135b29949",
   "metadata": {},
   "source": [
    "# Lectura desde una URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030623c8-7439-4f0b-859f-8cef740a9763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
